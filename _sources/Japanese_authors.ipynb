{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe44353",
   "metadata": {},
   "source": [
    "# Views on Japanese Authors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737a553",
   "metadata": {},
   "source": [
    "This notebook analyses the vocabulary used to describe male and female authors from Japan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a00d8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "import tdm\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "import PyPDF2 \n",
    "import ssl\n",
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize,sent_tokenize,pos_tag\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "## Frequently used words such as articles, pronouns and prepositions\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.extend(['/3','-+0','43+','/-1','m4/','https','//aboutjstororg/termsthis','-h1-3',\n",
    "'sayaka','isbn','muse','gmt','leiden','downloaded','//aboutjstororg/termsthis',                   \n",
    "'sanb˚e','tác','issn','murasaki','/aboutjstororg/termsthis','-h1-3' , 'gmailcom'])\n",
    "\n",
    "import string\n",
    "for punct_mark in string.punctuation:\n",
    "    stopword_list.append(punct_mark)\n",
    "    \n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_doi(DOI):\n",
    "    DOI = re.sub(r'[.]','#',DOI)\n",
    "    DOI = re.sub(r'\\/','=',DOI)\n",
    "    return DOI\n",
    "\n",
    "def decode_doi(DOI):\n",
    "    DOI = re.sub(r'#','.',DOI)\n",
    "    DOI = re.sub(r'=',r'\\/',DOI)\n",
    "    return DOI\n",
    "\n",
    "def get_filename(DOI):\n",
    "    DOI = re.sub(r'[\\.\\/-_]','',DOI)\n",
    "    return DOI\n",
    "\n",
    "doi_gender = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d747a56",
   "metadata": {},
   "source": [
    "We will consider the following authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "288cd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_authors = [\n",
    "'Haruki Murakami',\n",
    "'Sosuke Natsukawa',\n",
    "'Osamu Dazai',\n",
    "'Yukio Mishima',\n",
    "'Soseki Natsume',\n",
    "'Toshikazu Kawaguchi',\n",
    "'Junichiro Tanizaki',\n",
    "'Kenji Miyazawa',\n",
    "'Yasunari Kawabata',\n",
    "'Kobo Abe',\n",
    "'Ryu Murakami',\n",
    "'Tomihiko Morimi',\n",
    "'Keigo Higashino',\n",
    "'Kenzaburo Oe',\n",
    "'Tsutomu Minakami',\n",
    "'Ranpo Edogawa',\n",
    "'Shusaku Endo',\n",
    "'Seishi Yokomizo',\n",
    "'Genki Kawamura',\n",
    "'Kenko Yoshida' \n",
    "]\n",
    "\n",
    "female_authors = [ \n",
    "'Mieko Kawakami',\n",
    "'Hiromi Kawakami',\n",
    "'Yoko Tawada',\n",
    "'Natsuko Imamura',\n",
    "'Yuko Tsushima',\n",
    "'Sayaka Murata',\n",
    "'Yoko Ogawa',\n",
    "'Hiroko Oyamada',\n",
    "'Miri Yu',\n",
    "'Asako Yuzuki',\n",
    "'Sayaka Murata',\n",
    "'Banana Yoshimoto',\n",
    "'Yuko Tsushima',\n",
    "'Risa Wataya',\n",
    "'Mitsuyo Kakuta',\n",
    "'Natsuo Kirino',\n",
    "'Miyuki Miyabe',\n",
    "'Ichiyo Higuchi',\n",
    "'Riku Onda',\n",
    "'Murasaki Shikibu' \n",
    "]\n",
    "\n",
    "authors = male_authors + female_authors\n",
    "for author in authors:\n",
    "    first_name = author[:index_space].strip().lower()\n",
    "    last_name = author[index_space+1:].strip().lower()\n",
    "    stopword_list.append(first_name.lower())\n",
    "    stopword_list.append(last_name.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78ef21",
   "metadata": {},
   "source": [
    "## Collect references to articles using Crossref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82526246",
   "metadata": {},
   "source": [
    "This notebook collects academic publications using the Crossref API. Crossref is the organisation which mints and manages DOI for publications and datasets. \n",
    "\n",
    "More information about this API can be found on [Crossref's website](https://www.crossref.org/documentation/retrieve-metadata/rest-api/a-non-technical-introduction-to-our-api/)\n",
    "\n",
    "The base url of the API for academic publications is \n",
    "\n",
    "```\n",
    "https://api.crossref.org/works\n",
    "```\n",
    "\n",
    "The API can be used with the following parameters:\n",
    "\n",
    "* **query**: a term to search for. \n",
    "* **rows**: the number of publications to be included in the result set. The maximum number of rows is 500. \n",
    "* In the **filter**, it is possible to specify a start date using **from-pub-date**, and an end date using  **until-pub-date**. \n",
    "\n",
    "On the cell below, we collect references to academic works about each of the 20 authors that were selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(json_data):\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for item in json_data:\n",
    "        data = dict()\n",
    "\n",
    "        date = ''\n",
    "        date_parts = item['published']['date-parts'][0] \n",
    "        for i,part in enumerate(date_parts):\n",
    "            date += f'{part}'\n",
    "            if i < len(date_parts)-1:\n",
    "                date += '-'\n",
    "        data['date'] = date\n",
    "        \n",
    "        \n",
    "        if re.search(r'\\d{4}-\\d{1,2}-\\d{1,2}',date):\n",
    "            year = datetime.strptime(date, '%Y-%m-%d').year\n",
    "        elif re.search(r'\\d{4}-\\d{1,2}',date):\n",
    "            year = datetime.strptime(date, '%Y-%m').year\n",
    "        elif re.search(r'\\d{4}',date):\n",
    "            year = datetime.strptime(date, '%Y').year\n",
    "            \n",
    "        data['year'] = int(year)\n",
    "        \n",
    "        if 'author' in item:\n",
    "            authors = []\n",
    "            for author in item['author']:\n",
    "                author_name = ''\n",
    "                author_name += author.get('given','')\n",
    "                author_name += ' ' + author.get('family','')\n",
    "                authors.append(author_name.strip())\n",
    "            if len(authors)>0:\n",
    "                data['author'] = authors\n",
    "        data['doi'] = item['DOI']\n",
    "        if 'publisher' in item:\n",
    "            data['publisher'] = item['publisher']\n",
    "        \n",
    "        if 'subject' in item:\n",
    "      \n",
    "            subjects = []\n",
    "            for subject in item['subject']:\n",
    "                subjects.append(subject)\n",
    "            if len(subjects)>0:\n",
    "                data['subject'] = subjects\n",
    "        if 'abstract' in item:\n",
    "            data['abstract'] = item['abstract']     \n",
    "        if 'container-title' in item:\n",
    "            journal_title = item['container-title'][0]\n",
    "            journal_title = re.sub( '\\s+' , ' ' , str(journal_title) )\n",
    "            journal_title = re.sub( '\\s+&amp;\\s+' , ' & ' , str(journal_title) )\n",
    "            data['journal'] = journal_title\n",
    "#             discipline = journals_dict[journal_title]\n",
    "#             data['discipline'] = discipline\n",
    "        \n",
    "        data['type']=item['type']\n",
    "        if 'title' in item:\n",
    "            title = item['title'][0]\n",
    "        if 'subtitle' in item:\n",
    "            title += ': ' + item['subtitle'][0]\n",
    "        data['title']=title\n",
    "        if 'link' in item:\n",
    "            links = []\n",
    "            for url in item['link']:\n",
    "                links.append(url['URL'])\n",
    "            if len(links)>0:\n",
    "                data['link']=links\n",
    "        rows.append(data)\n",
    "        \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ae379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for author in authors:\n",
    "    print(author)\n",
    "    index_space = author.index(' ')\n",
    "    first_name = author[:index_space].strip()\n",
    "    last_name = author[index_space+1:].strip()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    query_nr = 0\n",
    "    query = urllib.parse.quote(author)\n",
    "    cursor = '*'\n",
    "    rows = 500\n",
    "    publ_type = 'journal-article'\n",
    "    start_date = '2013-01-01'\n",
    "    end_date = '2023-12-31'\n",
    "\n",
    "    headers = {'User-Agent':'mailto:p.a.f.verhaar@hum.leidenuniv.nl'}\n",
    "\n",
    "    url = f'https://api.crossref.org/works?query=%22{query}%22&cursor={cursor}&rows={rows}'\n",
    "\n",
    "    if re.search(r'\\d',start_date) and re.search(r'\\d',end_date):\n",
    "        url += f'&filter=type:{publ_type},from-pub-date:{start_date},until-pub-date:{end_date}'\n",
    "\n",
    "    print(url)\n",
    "\n",
    "    response = requests.get(url,headers=headers)\n",
    "    json_data = response.json()\n",
    "\n",
    "    print( f\"{json_data['message']['total-results']} results. \")\n",
    "    nr_items = len(json_data['message']['items'])\n",
    "\n",
    "    query_nr += 1\n",
    "    print(f\"{query_nr}: items {(query_nr*rows)-rows}-{query_nr*rows}\")\n",
    "\n",
    "\n",
    "    data = get_items(json_data['message']['items'])\n",
    "\n",
    "    for article in data:\n",
    "        \n",
    "        article_authors = ''\n",
    "        if 'author' in article:\n",
    "            json_authors = article['author']\n",
    "            for article_author in json_authors:\n",
    "                article_authors += article_author + ' '       \n",
    "                        \n",
    "        if not(re.search(r'{}'.format(last_name),str(article_authors))) and not(re.search(r'{}'.format(first_name),str(article_authors))):\n",
    "            article['author'] = author\n",
    "            results.append(article)\n",
    "            print(article['title'])\n",
    "       \n",
    "            \n",
    "    next_cursor = ''\n",
    "    if 'next-cursor' in json_data['message']:\n",
    "        next_cursor = json_data['message']['next-cursor']\n",
    "\n",
    "    while re.search( r'\\w+' , next_cursor) and nr_items>0:\n",
    "\n",
    "        url = f'https://api.crossref.org/works?query=%22{query}%22&cursor={next_cursor}&rows={rows}'\n",
    "\n",
    "        if re.search(r'\\d',start_date) and re.search(r'\\d',end_date):\n",
    "            url += f'&filter=type:{publ_type},from-pub-date:{start_date},until-pub-date:{end_date}'\n",
    "            print(url)\n",
    "        response = requests.get(url,headers=headers)\n",
    "        json_data = response.json()\n",
    "        query_nr += 1\n",
    "        print(f\"{query_nr}: items {(query_nr*rows)-rows}-{query_nr*rows}\")\n",
    "\n",
    "        if 'items' in json_data['message']:\n",
    "            nr_items = len(json_data['message']['items'])\n",
    "            data = get_items(json_data['message']['items'])\n",
    "            for article in data:\n",
    "\n",
    "                article_authors = ''\n",
    "                if 'author' in article:\n",
    "                    json_authors = article['author']\n",
    "                    for article_author in json_authors:\n",
    "                        article_authors += article_author + ' '    \n",
    "\n",
    "\n",
    "                if not(re.search(r'{}'.format(last_name),str(article_authors))) and not(re.search(r'{}'.format(first_name),str(article_authors))):\n",
    "                    article['author'] = author\n",
    "                    results.append(article)\n",
    "                    print(article['title'])\n",
    "\n",
    "        next_cursor = ''\n",
    "        if 'next-cursor' in json_data['message']:\n",
    "            next_cursor = json_data['message']['next-cursor']\n",
    "            \n",
    "    json_object = json.dumps(results, indent = 4) \n",
    "    with open(f'Corpus_Japanese/{author}_articles.json','w',encoding='utf-8') as out:\n",
    "        out.write(json_object)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(DOIs)} DOIs were found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe78899",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Corpus_japanese'\n",
    "\n",
    "DOIs_male = []\n",
    "DOIs_female = []\n",
    "author_names = []\n",
    "\n",
    "for a in male_authors:\n",
    "    json_file = open(os.path.join('Corpus_japanese','Authors',f'{a}_articles.json'),encoding='utf-8') \n",
    "    json_data = json.load(json_file)\n",
    "    \n",
    "    for item in json_data:\n",
    "        DOI = item['doi']\n",
    "        author_names.append(item['author'])\n",
    "        DOIs_male.append(DOI)\n",
    "        doi_gender[encode_doi(DOI)] = 'male' \n",
    "        \n",
    "for a in female_authors:\n",
    "    json_file = open(os.path.join('Corpus_japanese','Authors',f'{a}_articles.json'),encoding='utf-8') \n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "    for item in json_data:\n",
    "        DOI = item['doi']\n",
    "        author_names.append(item['author'])\n",
    "        DOIs_female.append(DOI)\n",
    "        doi_gender[encode_doi(DOI)] = 'female' \n",
    "        \n",
    "DOIs = DOIs_male+DOIs_female\n",
    "print(f'{len(DOIs)} DOIs were found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = [a for a in author_names if a in male_authors]\n",
    "print(f'{len(male)} articles by male authors were found.')\n",
    "      \n",
    "authors_freq = Counter(male)\n",
    "for author,count in authors_freq.most_common():\n",
    "    print(f'{author}: {count}')\n",
    "\n",
    "female = [a for a in author_names if a in female_authors]\n",
    "print(f'\\n\\n{len(female)} articles by female authors were found.')\n",
    "      \n",
    "authors_freq = Counter(female)\n",
    "for author,count in authors_freq.most_common():\n",
    "    print(f'{author}: {count}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981f08f",
   "metadata": {},
   "source": [
    "## Acquisition of PDF files \n",
    "\n",
    "The PDS of Open Access journals are downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_urls = dict()\n",
    "doi_title = dict()\n",
    "\n",
    "for DOI in DOIs:\n",
    "    url = f'http://api.crossref.org/works/{DOI}'\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    if response:\n",
    "        json_data = response.json()\n",
    "        message = json_data['message']\n",
    "        \n",
    "        title = ''\n",
    "        if 'title' in message:\n",
    "            title = message['title'][0]\n",
    "            doi_title[encode_doi(DOI)] = title\n",
    "            print(doi_title[encode_doi(DOI)])\n",
    "        \n",
    "        licence = 'Unknown'\n",
    "        if 'licence' in message:\n",
    "            for license in message['license']:\n",
    "                licence = license['URL']\n",
    "                \n",
    "        content_type = \"application/pdf\"\n",
    "        publ_url = 'unknown'\n",
    "        if 'link' in message:\n",
    "            publ_url = message['link'][0]['URL']\n",
    "            if 'content-type' in message['link'][0]:\n",
    "                download_urls[DOI] = (publ_url,content_type,licence)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for DOI in download_urls:\n",
    "    print(f'{DOI} => {encode_doi(DOI)}')\n",
    "\n",
    "    try:\n",
    "\n",
    "        file_name = encode_doi(DOI)\n",
    "        if re.search( r'xml$', download_urls[DOI][1] ):\n",
    "            file_name = f'{file_name.strip()}.xml'\n",
    "        else:\n",
    "            file_name = f'{file_name.strip()}.pdf'\n",
    " \n",
    "        publ_url = download_urls[DOI][0]\n",
    "        print(publ_url)\n",
    "        \n",
    "        if publ_url not in ['http://bcjjl.org/upload/pdf/bcjjlls-9-1-257.pdf',\n",
    "                           'https://ojs.badanbahasa.kemdikbud.go.id/jurnal/index.php/jentera/article/viewFile/3971/2114']:\n",
    "\n",
    "            text_response = requests.get(publ_url)\n",
    "            if text_response.status_code == 200:\n",
    "\n",
    "                path = os.path.join(directory,'Articles',file_name)\n",
    "                pdf = open(path, 'wb')\n",
    "                pdf.write(text_response.content)\n",
    "                pdf.close()\n",
    "                print(f'Download successful!')\n",
    "            else:\n",
    "                print(f'Issue with {publ_url}')\n",
    "                print(download_urls[DOI][2])\n",
    "                \n",
    "\n",
    "    except Exception as error:\n",
    "        print(f'Issue with {publ_url} {error}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1201bd1",
   "metadata": {},
   "source": [
    "The plain text is extracted from the PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(directory,'Articles',pdf) for pdf in os.listdir(os.path.join(directory,'Articles')) if re.search(r'pdf$',pdf)]\n",
    "                                                           \n",
    "non_pdf = []\n",
    "\n",
    "for pdf in files:\n",
    "    \n",
    "    full_text = ''\n",
    "    \n",
    "    try:\n",
    "        reader = PyPDF2.PdfFileReader(pdf)\n",
    "        for page in reader.pages:\n",
    "\n",
    "            page = reader.pages[0]\n",
    "            text = page.extractText()\n",
    "            text = re.sub(r'\\s+',' ',text.strip())\n",
    "            full_text += text\n",
    "\n",
    "        full_text = full_text.strip()\n",
    "        if len(full_text)>0:\n",
    "            lang = detect(full_text)                                                        \n",
    "            file_name = os.path.basename(pdf)\n",
    "            file_name = re.sub(r'[.]pdf$','',file_name)                                         \n",
    "            path = os.path.join(directory,'TXT',f'{file_name}_{lang}.txt')  \n",
    "                                                           \n",
    "            with open(path,'w',encoding='utf-8') as out:\n",
    "                out.write(full_text)\n",
    "        else:\n",
    "            non_pdf.append(pdf)\n",
    "    except:\n",
    "        non_pdf.append(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26823ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in non_pdf:\n",
    "    with open(path,encoding='utf-8') as fh:\n",
    "        try:\n",
    "            xml_file = fh.read()\n",
    "            soup = BeautifulSoup(xml_file, \"lxml\")\n",
    "            full_text = soup.find('body').text\n",
    "            if len(full_text)>0:\n",
    "                lang = detect(full_text)\n",
    "\n",
    "                                       \n",
    "                file_name = os.path.basename(path)\n",
    "                file_name = re.sub(r'[.]xml$','',file_name) \n",
    "                file_name = re.sub(r'[.]pdf$','',file_name) \n",
    "            \n",
    "                                                      \n",
    "                path = os.path.join(directory,'TXT',f'{file_name}_{lang}.txt')\n",
    "\n",
    "                with open(path,'w',encoding='utf-8') as out:\n",
    "                    out.write(full_text)\n",
    "        except:\n",
    "            print(f'Problem with {path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4a34e",
   "metadata": {},
   "source": [
    "There are articles in different languages. This notebook only focuses on the 51 Open Access academic articles in English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7852e460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\t45\n",
      "id\t12\n",
      "pt\t12\n",
      "de\t8\n",
      "es\t5\n",
      "ca\t5\n",
      "fr\t2\n",
      "pl\t2\n",
      "vi\t2\n",
      "da\t1\n",
      "th\t1\n"
     ]
    }
   ],
   "source": [
    "OA_dois = []\n",
    "\n",
    "files = os.listdir(os.path.join(directory,'TXT'))\n",
    "\n",
    "languages = []\n",
    "for file in files:\n",
    "    language = file[-6:-4]\n",
    "    languages.append(language)\n",
    "language_freq = Counter(languages)\n",
    "\n",
    "for language,count in language_freq.most_common():\n",
    "    if not(re.search('_',language)):\n",
    "        print(f\"{language}\\t{count}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2c5ab1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Articles on male Japanese authors:\n",
      "\n",
      "Two genre classification of Japanese literary works written by Ryuunosuke Akutagawa and Kenji Miyazawa based on word vectors\n",
      "Analysis Figure of Speech and Theatrical Story In No Longer Human Novel by Osamu Dazai\n",
      "Acceptance and Commitment Therapy is \"Haruki Murakami\"\n",
      "Analysis on Haruki Murakami's Barn Burning—Focusing on the Metaphor in the Story\n",
      "Mari Asai’s Personal Isolation in Haruki Murakami’s After Dark\n",
      "Analisis Sosiolinguistik Politeness Bahasa Jepang dalam Film Galileo 2013 Karya Keigo Higashino\n",
      "The applicability of Big Five facets and Dark Tetrad traits on Yukio Mishima’s novel protagonists\n",
      "The Hospital as An Ideological State Apparatus and Disciplinary Agent as Seen through the Main Character in Kenzaburo Oe�s A Personal Matter\n",
      "An Analysis of Stylistic in After Dark by Haruki Murakami\n",
      "Exploring the intersection of Anton Chekhov and Haruki Murakami: a slow reading analysis of “Drive My Car”\n",
      "A likely case of progression from mild cognitive impairment to dementia in Yasunari Kawabata's The Sound of the Mountain\n",
      "Haruki Murakami and the Transition of Modern Culture &amp;lt;br&amp;gt;—From the Perspective of Young Readers in East Asian Cities\n",
      "Meiji's New Women from the Perspective of Visual Fusion based on Soseki Natsume's Novel Sanshiro\n",
      "Social Function of Maxim to Present “Coming of Age” Value through Bildungsroman Novel Translation Entitled Norwegian Wood by Haruki Murakami\n",
      "Anxiety of Tengo Kawana in Town Of Cats Short Story by Haruki Murakami 2011\n",
      "\n",
      "English Articles on female Japanese authors:\n",
      "\n",
      "Eating Murasaki Shikibu: Scriptworlds, Reverse-Importation, and The Tale of Genji\n",
      "The (Un)known Epoch: Exploring Dystopian Japan in Yoko Tawada’s The Emissary\n",
      "An Interview with Mieko Kawakami\n",
      "The Thirty-Something “Tokyo Daughters” of Kawakami Hiromi’s Strange Weather in Tokyo, Shibasaki Tomoka’s Spring Garden, and Murata Sayaka’s Convenience Store Woman\n",
      "Woman Stereotype in the Novel Convenience Store  Woman by Sayaka Murata (2016)\n",
      "Happiness Foreclosed: Sentimentalism, the Suffering Heroine, and Social Critique in Higuchi Ichiyō's \"Jūsan'ya\"\n",
      "Beyond The Tale of Genji: Murasaki Shikibu as Icon and Exemplum in Seventeenth- and Eighteenth-Century Popular Japanese Texts for Women\n",
      "Androids for the Stone Age?: Individuality, Space, and Gender in Murata Sayaka's Convenience Store Woman\n",
      "The image of the main character in Sayaka Murata’s novel \"Convenience store woman\"\n",
      "The Shaping of Japan’s Collective Memory in Yoko Ogawa’s The Memory Police\n",
      "The Cult of Happiness: Maid, Housewife, and Affective Labor in Higuchi Ichiyō’s “Warekara”\n",
      "Mama Tomo dalam Novel Happiness Karya Natsuo Kirino\n",
      "Reading Matters - Materiality and (Il)legible Inscriptions in Yoko Tawada’s Das Bad\n",
      "Alienation, Embodiment, and Search for Authenticity Under Capitalism in Mieko Kawakami’s Breasts and Eggs\n",
      "“No More Translations”: Uncounting Languages in Yoko Tawada's <i>Memoirs of a Polar Bear</i>\n"
     ]
    }
   ],
   "source": [
    "files = [file for file in files if re.search('_en.txt',file)]\n",
    "dois = [re.sub('_en.txt','',file) for file in files]\n",
    "\n",
    "## The following toll access articles have been added\n",
    "## To ensure that there is balance between the number of articles\n",
    "## in teh two groups. \n",
    "\n",
    "doi_gender['emw26431282']= 'female'\n",
    "doi_gender['jwl-article-p259_9'] = 'female'\n",
    "doi_gender['1010800955580320161189448'] = 'female'\n",
    "doi_gender['101353jjs20150024'] = 'female'\n",
    "doi_gender['25064492'] = 'female'\n",
    "doi_gender['27159896'] = 'female'\n",
    "doi_gender['855558'] = 'female'\n",
    "doi_gender['1010800955580320191614648'] = 'female'\n",
    "doi_gender['1010800269005520201721115'] = 'female'\n",
    "doi_gender['101111gequ12032'] = 'female'\n",
    "\n",
    "doi_title['emw26431282']= 'Beyond The Tale of Genji: Murasaki Shikibu as Icon and Exemplum in Seventeenth- and Eighteenth-Century Popular Japanese Texts for Women'\n",
    "doi_title['jwl-article-p259_9'] = 'Eating Murasaki Shikibu: Scriptworlds, Reverse-Importation, and The Tale of Genji'\n",
    "doi_title['1010800955580320161189448'] = 'Invoking affect in Kawakami Mieko\\'s Chihi to ran (Breasts and Eggs, 2008): Higuchi Ichiyô, playful words and ludic gestures'\n",
    "doi_title['101353jjs20150024'] = 'The Cult of Happiness: Maid, Housewife, and Affective Labor in Higuchi Ichiyō’s “Warekara”'\n",
    "doi_title['25064492'] = 'Happiness Foreclosed: Sentimentalism, the Suffering Heroine, and Social Critique in Higuchi Ichiyō\\'s \"Jūsan\\'ya\"'\n",
    "doi_title['27159896'] = 'The Thirty-Something “Tokyo Daughters” of Kawakami Hiromi’s Strange Weather in Tokyo, Shibasaki Tomoka’s Spring Garden, and Murata Sayaka’s Convenience Store Woman'\n",
    "doi_title['855558'] = 'Androids for the Stone Age?: Individuality, Space, and Gender in Murata Sayaka\\'s Convenience Store Woman'\n",
    "doi_title['1010800955580320191614648'] = 'Fidelity to the dead: the question of complicity in Tsushima Yûko\\’s Wildcat Dome'\n",
    "doi_title['1010800269005520201721115'] = 'An Interview with Mieko Kawakami'\n",
    "doi_title['101111gequ12032'] = 'Representations of Public Spaces and the Construction of Race in Yoko Tawada\\’s “Bioskoop der Nacht”'\n",
    "\n",
    "gender = Counter()\n",
    "all_gender = []\n",
    "\n",
    "male_dois = []\n",
    "female_dois = []\n",
    "#print(len(female_dois))\n",
    "\n",
    "for doi in dois:\n",
    "    if doi_gender[doi] == 'male':\n",
    "        male_dois.append(doi)\n",
    "    elif doi_gender[doi] == 'female':\n",
    "        female_dois.append(doi)\n",
    "\n",
    "\n",
    "male_dois = male_dois[:15]\n",
    "female_dois = female_dois[:15]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('English Articles on male Japanese authors:\\n')\n",
    "\n",
    "for doi in male_dois:\n",
    "    print(doi_title[doi])\n",
    "    \n",
    "    \n",
    "\n",
    "print('\\nEnglish Articles on female Japanese authors:\\n')\n",
    "\n",
    "for doi in female_dois:\n",
    "    print(doi_title[doi])\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d25ec",
   "metadata": {},
   "source": [
    "## Text Mining\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "79b71d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wordlist(words):\n",
    "    words = [word for word in words if word not in stopword_list]\n",
    "    words = [word for word in words if len(word.strip())>2]\n",
    "    words = [re.sub(r'([….])|(\\')','',word) for word in words]\n",
    "    words = [word for word in words if len(re.sub(r'(\\d)|([\\/\\+\\-,:])','',word))>0]\n",
    "    words = [word.lower() for word in words if re.search(r'\\w', word)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ed7e22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_freq = Counter()\n",
    "female_freq = Counter()\n",
    "\n",
    "corpus_male = []\n",
    "corpus_female = []\n",
    "\n",
    "for doi in male_dois: \n",
    "    path = os.path.join('Corpus_Japanese','TXT',f'{doi}_en.txt')\n",
    "    corpus_male.append(path)\n",
    "\n",
    "    text = open(path,encoding='utf-8')\n",
    "    full_text = text.read()\n",
    "    words = word_tokenize(full_text.lower())\n",
    "    words = clean_wordlist(words)\n",
    "    male_freq.update(words)\n",
    "    \n",
    "for doi in female_dois: \n",
    "    path = os.path.join('Corpus_Japanese','TXT',f'{doi}_en.txt')\n",
    "    corpus_female.append(path)\n",
    "\n",
    "    text = open(path,encoding='utf-8')\n",
    "    full_text = text.read()\n",
    "    words = word_tokenize(full_text.lower())\n",
    "    words = clean_wordlist(words)\n",
    "    female_freq.update(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d952a8",
   "metadata": {},
   "source": [
    "### Most frequent words in articles on male authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4a4bfed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keigo => 288\n",
      "murakami => 270\n",
      "story => 263\n",
      "haruki => 257\n",
      "novel => 188\n",
      "used => 173\n",
      "study => 172\n",
      "use => 146\n",
      "literary => 133\n",
      "literature => 132\n",
      "hospital => 131\n",
      "short => 126\n",
      "life => 125\n",
      "research => 122\n",
      "anxiety => 115\n",
      "language => 110\n",
      "based => 109\n",
      "mono => 108\n",
      "work => 107\n",
      "social => 102\n",
      "translation => 100\n",
      "town => 98\n",
      "cats => 98\n",
      "people => 95\n",
      "abstract => 94\n",
      "japanese => 94\n",
      "speech => 90\n",
      "data => 89\n",
      "world => 85\n",
      "theory => 83\n"
     ]
    }
   ],
   "source": [
    "for word,count in male_freq.most_common(30):\n",
    "    print(f'{word} => {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020533e4",
   "metadata": {},
   "source": [
    "### Most frequent words in articles on female authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "581f061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genji => 315\n",
      "women => 244\n",
      "tale => 235\n",
      "japanese => 230\n",
      "mama => 162\n",
      "group => 136\n",
      "monogatari => 128\n",
      "university => 121\n",
      "tomo => 117\n",
      "dan => 117\n",
      "novel => 109\n",
      "shikibu => 98\n",
      "three => 96\n",
      "minamoto => 96\n",
      "read => 85\n",
      "readers => 78\n",
      "study => 76\n",
      "society => 70\n",
      "alienation => 70\n",
      "long => 69\n",
      "literature => 68\n",
      "female => 68\n",
      "world => 67\n",
      "subject => 67\n",
      "journal => 66\n",
      "translation => 65\n",
      "tales => 65\n",
      "japan => 64\n",
      "fictional => 64\n",
      "jewels => 64\n"
     ]
    }
   ],
   "source": [
    "for word,count in female_freq.most_common(30):\n",
    "    print(f'{word} => {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de84b9",
   "metadata": {},
   "source": [
    "### Words used ONLY in articles on male authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "76ae31d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keigo\n",
      "hospital\n",
      "mono\n",
      "town\n",
      "cats\n",
      "speech\n",
      "data\n",
      "bird\n",
      "entitled\n",
      "tengo\n",
      "kawana\n",
      "universitas\n",
      "utterance\n",
      "namely\n",
      "bahasa\n",
      "galileo\n",
      "sonkeigo\n",
      "kenjougo\n",
      "teineigo\n",
      "sachiko\n",
      "uchi\n",
      "partners\n",
      "soto\n",
      "google\n",
      "qualitative\n",
      "disciplinary\n",
      "baby\n",
      "results\n",
      "humans\n",
      "speaker\n",
      "tells\n"
     ]
    }
   ],
   "source": [
    "for word,count in male_freq.most_common(100):\n",
    "    if word not in female_freq.keys():\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8ec8b",
   "metadata": {},
   "source": [
    "### Words used ONLY in articles on female authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5e5c6dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genji\n",
      "women\n",
      "mama\n",
      "monogatari\n",
      "tomo\n",
      "shikibu\n",
      "minamoto\n",
      "alienation\n",
      "tales\n",
      "jewels\n",
      "tamenori\n",
      "project\n",
      "kelompok\n",
      "authenticity\n",
      "stratification\n",
      "embodiment\n",
      "multan\n",
      "existentialism\n",
      "classic\n",
      "script\n",
      "prose\n",
      "complex\n",
      "indeed\n",
      "breasts\n",
      "eggs\n",
      "lumc\n",
      "primarily\n",
      "audience\n",
      "body\n",
      "feminist\n",
      "heian\n",
      "widely\n",
      "exceedingly\n",
      "identified\n",
      "remain\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "for word,count in female_freq.most_common(100):\n",
    "    if word not in male_freq.keys() and word not in stopword_list:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec21fc",
   "metadata": {},
   "source": [
    "### Distinctive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2af93080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_frequencies(corpus):\n",
    "\n",
    "    freq = Counter()\n",
    "    for text in corpus:\n",
    "        full_text = ''\n",
    "        file_handler = open(text,encoding='utf-8')\n",
    "        full_text = file_handler.read()\n",
    "        words = word_tokenize(full_text.lower())\n",
    "        words = clean_wordlist(words)\n",
    "        freq.update(words)\n",
    "\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5dbfe04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tm import log_likelihood, sorted_by_value\n",
    "\n",
    "freq1 = calculate_word_frequencies(corpus_male)\n",
    "total1 = sum(freq1.values())\n",
    "\n",
    "freq2 = calculate_word_frequencies(corpus_female)\n",
    "total2 = sum(freq2.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5affcd6",
   "metadata": {},
   "source": [
    "Which used are used most frequently in the articles on male authors, if compared to the frequencies in the articles by female authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f95a1d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story 247.6425196137883\n",
      "anxiety 124.2423122895864\n",
      "short 117.74403588215971\n",
      "used 94.95588141183018\n",
      "life 69.49439825131792\n",
      "distance 68.84101651591166\n",
      "age 65.93393389170957\n",
      "show 63.29409716376378\n",
      "literary 60.024981089818354\n",
      "based 57.60774896193466\n",
      "research 57.25547459329998\n",
      "film 56.869596542069296\n",
      "date 55.73916365170223\n",
      "power 54.93643289903723\n",
      "find 54.46559815629393\n",
      "ideology 52.35185931119826\n",
      "language 51.479526920351255\n",
      "position 51.17234412030269\n",
      "less 50.07700074937955\n",
      "man 49.680334395854956\n",
      "gmailcom 47.77114521987985\n",
      "person 47.54977867824978\n",
      "said 46.72128755682202\n",
      "works 45.975890819025764\n",
      "state 42.35336596497723\n"
     ]
    }
   ],
   "source": [
    "ll_scores = dict()\n",
    "\n",
    "\n",
    "for word in freq1.keys():\n",
    "    if word in freq2.keys():\n",
    "\n",
    "        ll_score = log_likelihood( freq1[word] , freq2[word] , total1 , total2 )\n",
    "        ll_scores[word] = ll_score\n",
    "\n",
    "max = 25\n",
    "i = 0 \n",
    "        \n",
    "for word in sorted_by_value(ll_scores , ascending = False ):\n",
    "    print( word , ll_scores[word] )\n",
    "    i += 1\n",
    "    if i == max: \n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738e72a",
   "metadata": {},
   "source": [
    "Which used are used most frequently in the articles on female authors, if compared to the frequencies in the articles by male authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "de043593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tale -355.2148053016438\n",
      "female -101.80434048822103\n",
      "trans -95.38986561733938\n",
      "japanese -95.1039315670825\n",
      "woman -87.38272921675936\n",
      "three -83.6278703328577\n",
      "fictional -83.5553715861997\n",
      "subject -83.34135724314697\n",
      "long -81.95573302709406\n",
      "dan -66.17274195400381\n",
      "read -64.40541008194549\n",
      "group -63.95780285049318\n",
      "wrote -57.585761646409985\n",
      "early -50.06422410274898\n",
      "male -44.482261276463966\n",
      "discussed -44.482261276463966\n",
      "content -44.400703769469345\n",
      "called -40.91223864948137\n",
      "century -40.32798614708028\n",
      "texts -38.89699846335773\n",
      "class -38.210142799706965\n",
      "english -38.10160250502497\n",
      "perhaps -37.47128609092386\n",
      "rich -36.758473469073415\n",
      "although -36.587193270625235\n"
     ]
    }
   ],
   "source": [
    "max = 25\n",
    "i = 0 \n",
    "\n",
    "for word in sorted_by_value(ll_scores ) :\n",
    "    print( word , ll_scores[word] )\n",
    "    i += 1\n",
    "    if i == max:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f28556c",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "\n",
    "Which adjectives are used most frequently in articles on male authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "720e8452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literary 131\n",
      "short 126\n",
      "novel 118\n",
      "social 102\n",
      "japanese 94\n",
      "human 71\n",
      "hospital 65\n",
      "universitas 64\n",
      "uchi 54\n",
      "qualitative 52\n",
      "disciplinary 52\n",
      "main 49\n",
      "different 47\n",
      "abstract 44\n",
      "acceptable 42\n",
      "readable 42\n",
      "superego 42\n",
      "personal 41\n",
      "structural 41\n",
      "various 38\n"
     ]
    }
   ],
   "source": [
    "male_adjectives = []\n",
    "male_nouns = []\n",
    "\n",
    "for doi in male_dois: \n",
    "    path = os.path.join('Corpus_Japanese','TXT',f'{doi}_en.txt')\n",
    "    text = open(path,encoding='utf-8')\n",
    "    full_text = text.read()\n",
    "    words = word_tokenize(full_text.lower())\n",
    "    words = clean_wordlist(words)\n",
    "    \n",
    "    pos = pos_tag(words)\n",
    "\n",
    "    for p in pos:\n",
    "        if re.search( '^JJ',p[1] ):\n",
    "            male_adjectives.append(p[0])\n",
    "        if re.search( '^NN',p[1] ):\n",
    "            male_nouns.append(p[0])\n",
    "\n",
    "adj_freq_male = Counter(male_adjectives)\n",
    "for w,c in adj_freq_male.most_common(20):\n",
    "    print(w,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723669f",
   "metadata": {},
   "source": [
    "Which adjectives are used most frequently in articles on female authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b6448e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japanese 229\n",
      "tale 166\n",
      "novel 67\n",
      "female 67\n",
      "fictional 64\n",
      "tamenori 64\n",
      "english 63\n",
      "new 55\n",
      "subject 52\n",
      "many 42\n",
      "classic 40\n",
      "social 38\n",
      "early 37\n",
      "popular 37\n",
      "mama 36\n",
      "complex 35\n",
      "prose 35\n",
      "cultural 34\n",
      "least 34\n",
      "modern 33\n",
      "rich 33\n",
      "heian 33\n",
      "prominent 33\n",
      "entire 33\n",
      "abstract 32\n",
      "dystopian 32\n",
      "exemplum 32\n",
      "seventeenth- 32\n",
      "eighteenth- 32\n",
      "major 32\n",
      "lady-in-waiting 32\n",
      "empress 32\n",
      "syllabic 32\n",
      "ﬁwoman™s 32\n",
      "discussed 32\n",
      "exclusive 32\n",
      "murasaki™s 32\n",
      "generic 32\n",
      "male 32\n",
      "highest 32\n",
      "edward 32\n",
      "center 32\n",
      "michigan 32\n",
      "hotaru 32\n",
      "tamakazura 32\n",
      "typical 32\n",
      "tyler 32\n",
      "international 30\n",
      "=2- 30\n",
      "a-d 30\n",
      "e+/0 30\n",
      "0-e+ 30\n",
      "l-m- 30\n",
      "nc=c1co+ 30\n",
      "e-2 30\n",
      ":42rsr 30\n",
      "t-3+ 30\n",
      "feminist 29\n",
      "human 26\n",
      "literary 24\n",
      "emissary 24\n",
      "environmental 24\n",
      "apocalyptic 24\n",
      "foreign 23\n",
      "main 23\n",
      "chinese 20\n",
      "genji 19\n",
      "available 19\n",
      "write 18\n",
      "informal 18\n",
      "penelitian 18\n",
      "sosial 18\n",
      "ukuran 18\n",
      "february 17\n",
      "domestic 16\n",
      "different 16\n",
      "philosophical 16\n",
      "contemporary 16\n",
      "financial 15\n",
      "bad 15\n",
      "national 14\n",
      "public 14\n",
      "aniqua 14\n",
      "munawar 14\n",
      "chaudhary 14\n",
      "dime 14\n",
      "workforce 14\n",
      "invidious 14\n",
      "patriarchal 14\n",
      "strait 14\n",
      "eggs 14\n",
      "unveil 14\n",
      "embodiment 14\n",
      "faith 14\n",
      "quest 14\n",
      "authentic 14\n",
      "obtainable 14\n",
      "small 13\n",
      "live 13\n",
      "//ijlcwumedupk/indexphp/ojsinternational 13\n",
      "™smemoirsofapolarbear 13\n",
      "pennyyeungisaphdcandidateincom- 13\n",
      "translationstudiesinmultilingual 13\n",
      "memoirsofapolar 13\n",
      "thesepassagesfromthebook 13\n",
      "ienteredthestorybeingtoldasitspro- 13\n",
      "boldpro- 13\n",
      "nouncementswescarcelythinkofaspropertothememoir 13\n",
      "memoirsofapolarbear 13\n",
      "novelisticlifeoftheirown 13\n",
      "theyannouncethepreferredcompositionalstrategiesoftheprotag- 13\n",
      "andwhoistryingtoresolvethe 13\n",
      "linguisticconundrumarisingfromhermigrationacrossgeographic 13\n",
      "writingmylifeinseverallanguagesatthesametime 13\n",
      "notonlythepolarbear 13\n",
      "™sauthorhasbeen 13\n",
      "addressinginhervastbodyofworktawada 13\n",
      "whomovedto 13\n",
      "germanyfromjapanin1982atagetwenty-two 13\n",
      "hasdrawnanenor- 13\n",
      "mouscreativeenergyfromwhatthebear-protagonistpresentsasa 13\n",
      "ﬁbeinganovelistitwouldbemucheasier 13\n",
      "western 11\n",
      "whole 11\n",
      "due 10\n",
      "original 10\n",
      "massive 10\n",
      "elderly 10\n",
      "e-journal 10\n",
      "d14/ 10\n",
      "g4- 10\n",
      "l2- 10\n",
      "s27 10\n",
      "w4-4 10\n",
      "uzbek 10\n",
      "autobiographical 10\n",
      "ushbu 10\n",
      "cbcf6f6f6dcg 10\n",
      "8-/h 10\n",
      "8-i 10\n",
      "+0i03- 10\n",
      "m8- 10\n",
      "-0= 10\n",
      ",8+a= 10\n",
      "p/3- 10\n",
      "/-a 10\n",
      "ancient 9\n",
      "great 9\n",
      "complete 9\n",
      "famous 9\n",
      "high 9\n",
      "first 9\n",
      "xian 9\n",
      "natural 9\n",
      "outside 9\n",
      "mean 9\n",
      "pebruari 9\n",
      "anuary 9\n",
      "ari 9\n",
      "sulatri 9\n",
      "budaya 9\n",
      "descriptive 9\n",
      "analyzed 9\n",
      "wellek 9\n",
      "theory 9\n",
      "goodman 9\n",
      "ideal 9\n",
      "honne 9\n",
      "ordinary 9\n",
      "common 9\n",
      "upper 9\n",
      "foun 9\n",
      "lifestyle 9\n",
      "tomo 9\n",
      "digunakan 9\n",
      "deskriptif 9\n",
      "sastra 9\n",
      "karakteristik 9\n",
      "dan 9\n",
      "berdasarkan 9\n",
      "kelompok 9\n",
      "ditemukan 9\n",
      "ibuki 9\n",
      "arisa 9\n",
      "little 8\n",
      "difficult 8\n",
      "suematsu 8\n",
      "literaria 8\n",
      "interdisciplinary 8\n",
      "january 8\n",
      "seng 8\n",
      "irreparable 8\n",
      "glimpse 8\n",
      "cial 8\n",
      "sick 8\n",
      "delic 8\n",
      "inhabitable 8\n",
      "strict 8\n",
      "yoshiro 8\n",
      "mumei 8\n",
      "futuristic 8\n",
      "dysfunctional 8\n",
      "regressive 8\n",
      "unknown 8\n",
      "tokyo 8\n",
      "rural 8\n",
      "nagano 8\n",
      "uninhabitable 8\n",
      "multiple 8\n",
      "pernicious 8\n",
      "lengthy 8\n",
      "single 7\n",
      "native 7\n",
      "important 7\n",
      "much 7\n",
      "young 7\n",
      "novelistic 6\n",
      "text 6\n",
      "japan 6\n",
      "able 6\n",
      "current 6\n",
      "formal 5\n",
      "several 5\n",
      "read 5\n",
      "classical 5\n",
      "similar 5\n",
      "poem 5\n",
      "con- 5\n",
      "journal 5\n",
      "naira 5\n",
      "april 5\n",
      "prestigious 5\n",
      "iterary 5\n",
      "reveal 5\n",
      "open 5\n",
      "obrazi 5\n",
      "zlar 5\n",
      "mentaliteti 5\n",
      "bosh 5\n",
      "ishlangan 5\n",
      "roman 5\n",
      "ulardan 5\n",
      "nufuzli 5\n",
      "bir 5\n",
      "teacher 5\n",
      "university 5\n",
      "old 4\n",
      "west 4\n",
      "late 4\n",
      "phonetic 4\n",
      "second 4\n",
      "interested 4\n",
      "realm 4\n",
      "present 4\n",
      "ideological 4\n",
      "extraordinary 4\n",
      "affordable 4\n",
      "short 4\n",
      "impossible 4\n",
      "huge 4\n",
      "know 4\n",
      "right 4\n",
      "light 4\n",
      "brazilian 3\n",
      "recent 3\n",
      "parallel 3\n",
      "particular 3\n",
      "nineteenth 3\n",
      "linguistic 3\n",
      "typographical 3\n",
      "easier 3\n",
      "influential 3\n",
      "global 3\n",
      "special 3\n",
      "peculiar 3\n",
      "larger 3\n",
      "waley 3\n",
      "tanizaki 3\n",
      "critical 3\n",
      "symbolic 3\n",
      "certain 3\n",
      "past 3\n",
      "see 3\n",
      "naked 3\n",
      "dialect 3\n",
      "title 2\n",
      "creative 2\n",
      "texts 2\n",
      "best 2\n",
      "unique 2\n",
      "cannibal 2\n",
      "andrade 2\n",
      "comprehensive 2\n",
      "commercial 2\n",
      "readership 2\n",
      "subsequent 2\n",
      "aesthetic 2\n",
      "elite 2\n",
      "hiragana 2\n",
      "understand 2\n",
      "essential 2\n",
      "so-called 2\n",
      "discrete 2\n",
      "semantic 2\n",
      "shakespeare 2\n",
      "familiar 2\n",
      "political 2\n",
      "unequal 2\n",
      "historical 2\n",
      "large 2\n",
      "enormous 2\n",
      "powerful 2\n",
      "poor 2\n",
      "british 2\n",
      "east 2\n",
      "asian 2\n",
      "appetite 2\n",
      "traditional 2\n",
      "reasonable 2\n",
      "wealthy 2\n",
      "accessible 2\n",
      "definitive 2\n",
      "lit- 2\n",
      "thirty 2\n",
      "lished 2\n",
      "triple 2\n",
      "perceive 2\n",
      "precise 2\n",
      "future 2\n",
      "personal 2\n",
      "poetic 2\n",
      "portable 2\n",
      "sure 2\n",
      "long 2\n",
      "heterosexual 2\n",
      "possible 2\n",
      "side 2\n",
      "hard 2\n",
      "die 2\n",
      "clean 2\n",
      "process 2\n",
      "under- 2\n",
      "fantasy 2\n",
      "magic 2\n",
      "serious 2\n",
      "sensual 2\n",
      "anglophone 1\n",
      "script 1\n",
      "brazil 1\n",
      "portuguese 1\n",
      "potential 1\n",
      "described 1\n",
      "enemy 1\n",
      "fellow 1\n",
      "nourish 1\n",
      "incorporating—admirable 1\n",
      "dietary 1\n",
      "figurative 1\n",
      "williams 1\n",
      "anglo-european 1\n",
      "seventy 1\n",
      "release 1\n",
      "oscar-winning 1\n",
      "lambs 1\n",
      "man-eating 1\n",
      "protégé 1\n",
      "martial 1\n",
      "shikibu1 1\n",
      "puzzle 1\n",
      "interregional 1\n",
      "geographic 1\n",
      "diachronic 1\n",
      "rowley 1\n",
      "context 1\n",
      "industrial 1\n",
      "employed 1\n",
      "artistic 1\n",
      "scholarship 1\n",
      "relevant 1\n",
      "overseas 1\n",
      "situate 1\n",
      "regional 1\n",
      "nourishment 1\n",
      "buddhist 1\n",
      "sought 1\n",
      "archipelago 1\n",
      "sixth 1\n",
      "spent 1\n",
      "life—which 1\n",
      "imperial 1\n",
      "spoken 1\n",
      "usage 1\n",
      "hiragana-type 1\n",
      "immediate 1\n",
      "distribute 1\n",
      "form 1\n",
      "truthfulness 1\n",
      "thirteenth 1\n",
      "ancestral 1\n",
      "employ 1\n",
      "amongst 1\n",
      "premodern 1\n",
      "foundational 1\n",
      "notion 1\n",
      "shift 1\n",
      "pure 1\n",
      "david 1\n",
      "ninth 1\n",
      "distinct 1\n",
      "questioned 1\n",
      "visual 1\n",
      "undervalue 1\n",
      "fevered 1\n",
      "territorial 1\n",
      "indebtedness 1\n",
      "attempted 1\n",
      "depict 1\n",
      "diary 1\n",
      "teach 1\n",
      "sutra 1\n",
      "playful 1\n",
      "allusion 1\n",
      "myriad 1\n",
      "scripts 1\n",
      "latin 1\n",
      "similarly 1\n",
      "untranslated 1\n",
      "deceptive 1\n",
      "tidy 1\n",
      "narration 1\n",
      "insertion 1\n",
      "typographic 1\n",
      "millennium-old 1\n",
      "400-year-old 1\n",
      "genji—which 1\n",
      "plot 1\n",
      "shakespearian 1\n",
      "incredible 1\n",
      "conversant 1\n",
      "shōyō 1\n",
      "must-read 1\n",
      "plentiful 1\n",
      "unreadable 1\n",
      "didactic 1\n",
      "antecedent 1\n",
      "advanced 1\n",
      "xiao 1\n",
      "customary 1\n",
      "tsubouchi 1\n",
      "fujioka 1\n",
      "kokubungaku 1\n",
      "greatest 1\n",
      "acclaim 1\n",
      "commentarial 1\n",
      "vibrant 1\n",
      "japaneseness 1\n",
      "argue 1\n",
      "cohesive 1\n",
      "quasi-isolationist 1\n",
      "penchant 1\n",
      "britain 1\n",
      "unfair 1\n",
      "universe 1\n",
      "driven 1\n",
      "principal 1\n",
      "give 1\n",
      "strive 1\n",
      "equal 1\n",
      "known 1\n",
      "contact 1\n",
      "opportune 1\n",
      "vertical 1\n",
      "standardized 1\n",
      "reviewer 1\n",
      "spectator 1\n",
      "tedious 1\n",
      "excessive 1\n",
      "conservative 1\n",
      "caddeau 1\n",
      "key 1\n",
      "tokugawa 1\n",
      "partial 1\n",
      "negative 1\n",
      "lambasted 1\n",
      "meaningless 1\n",
      "well-regarded 1\n",
      "less 1\n",
      "movable 1\n",
      "influenced 1\n",
      "undertaken 1\n",
      "oriental 1\n",
      "masterful 1\n",
      "joyce 1\n",
      "become 1\n",
      "free 1\n",
      "enough 1\n",
      "akin 1\n",
      "sukehiro 1\n",
      "colonized 1\n",
      "subvert 1\n",
      "supremacy 1\n",
      "european 1\n",
      "extensive 1\n",
      "america 1\n",
      "enjoy 1\n",
      "38-volume 1\n",
      "translation 1\n",
      "sekai 1\n",
      "dynic 1\n",
      "nagamine 1\n",
      "par 1\n",
      "yūsaku 1\n",
      "notice 1\n",
      "saw 1\n",
      "friend 1\n",
      "novelist-turned-translator 1\n",
      "request 1\n",
      "catapulted 1\n",
      "shikibu 1\n",
      "subscription 1\n",
      "clear 1\n",
      "promotional 1\n",
      "haul 1\n",
      "launch 1\n",
      "meet 1\n",
      "empty-handed 1\n",
      "hybrid 1\n",
      "largest 1\n",
      "bold 1\n",
      "perform 1\n",
      "top 1\n",
      "critic 1\n",
      "general 1\n",
      "fortunate 1\n",
      "misunderstood 1\n",
      "perennial 1\n",
      "japanese—remain 1\n",
      "bastion 1\n",
      "textual 1\n",
      "draw 1\n",
      "millennium 1\n",
      "shifts 1\n",
      "reverse-importation8 1\n",
      "describe 1\n",
      "helpful 1\n",
      "follow-up 1\n",
      "and—while 1\n",
      "underpin 1\n",
      "multi-sectored 1\n",
      "sushi 1\n",
      "genji-inspired 1\n",
      "ritz-carlton 1\n",
      "description 1\n",
      "vis-à-vis 1\n",
      "enriched 1\n",
      "erary 1\n",
      "guest 1\n",
      "pub- 1\n",
      "united 1\n",
      "excerpt 1\n",
      "tsunami 1\n",
      "nuclear 1\n",
      "literature 1\n",
      "archive 1\n",
      "narrate 1\n",
      "bigger 1\n",
      "memory 1\n",
      "par- 1\n",
      "ticular 1\n",
      "relation- 1\n",
      "func- 1\n",
      "audio 1\n",
      "ring- 1\n",
      "answer 1\n",
      "one-woman 1\n",
      "passage 1\n",
      "continuous 1\n",
      "happen 1\n",
      "obvious 1\n",
      "cata- 1\n",
      "strophic 1\n",
      "primary 1\n",
      "extreme 1\n",
      "phys- 1\n",
      "some- 1\n",
      "material 1\n",
      "left 1\n",
      "hav- 1\n",
      "logic 1\n",
      "subconscious 1\n",
      "tend 1\n",
      "explosive 1\n",
      "etc 1\n",
      "brim 1\n",
      "younger 1\n",
      "take-off 1\n",
      "speak 1\n",
      "spend 1\n",
      "poet 1\n",
      "step- 1\n",
      "library 1\n",
      "feels 1\n",
      "nected 1\n",
      "represent 1\n",
      "come 1\n",
      "conventional 1\n",
      "alive 1\n",
      "endless 1\n",
      "hap- 1\n",
      "crazy 1\n",
      "colour 1\n",
      "exceptional 1\n",
      "illuminated 1\n",
      "loneliness 1\n",
      "alone 1\n",
      "paradoxical 1\n",
      "absurd 1\n",
      "older 1\n",
      "clear-cut 1\n",
      "sentō 1\n",
      "pee 1\n",
      "lat- 1\n",
      "conceptual 1\n",
      "stem 1\n",
      "mean- 1\n",
      "visible 1\n",
      "foot 1\n",
      "thinking 1\n",
      "interesting 1\n",
      "landscape 1\n",
      "newborn 1\n",
      "fashionable 1\n",
      "super 1\n",
      "extra 1\n",
      "longer 1\n",
      "spectrum 1\n",
      "dirty 1\n",
      "dirt 1\n",
      "used 1\n",
      "sucked 1\n",
      "dead 1\n",
      "skin 1\n",
      "tub 1\n",
      "happy 1\n",
      "head 1\n",
      "told 1\n",
      "terrified 1\n",
      "grand- 1\n",
      "understood 1\n",
      "per- 1\n",
      "pres- 1\n",
      "easy 1\n",
      "acceptable 1\n",
      "sexual 1\n",
      "outspoken 1\n",
      "rep- 1\n",
      "resent 1\n",
      "messy 1\n",
      "ask 1\n",
      "next 1\n",
      "oppressive 1\n",
      "encour- 1\n",
      "call 1\n",
      "backlash 1\n",
      "thought 1\n",
      "true 1\n",
      "discrimi- 1\n",
      "institutional 1\n",
      "injustice 1\n",
      "care 1\n",
      "book-length 1\n",
      "rare 1\n",
      "joint 1\n",
      "favorite 1\n",
      "online 1\n",
      "essay 1\n",
      "harakiri 1\n",
      "eccentric 1\n",
      "neighbours 1\n",
      "epoch-making 1\n",
      "influ- 1\n",
      "chal- 1\n",
      "imaginative 1\n",
      "fable 1\n",
      "protagonist 1\n",
      "ladder 1\n",
      "inside 1\n",
      "survive 1\n",
      "narrative 1\n",
      "metaphysical 1\n",
      "orig- 1\n",
      "inal 1\n",
      "yur- 1\n",
      "iko 1\n",
      "real 1\n",
      "full 1\n",
      "ninjō 1\n",
      "child 1\n",
      "middle-aged 1\n",
      "stereotype 1\n",
      "actual 1\n",
      "comedic 1\n",
      "double 1\n",
      "funny 1\n",
      "straight-man 1\n",
      "sidekick 1\n",
      "nori-tsukomi 1\n",
      "one-man 1\n",
      "formed 1\n",
      "collo- 1\n",
      "quial 1\n",
      "silent 1\n",
      "differ- 1\n",
      "aloud 1\n",
      "simul- 1\n",
      "ver- 1\n",
      "dialogue 1\n",
      "standard 1\n",
      "turn 1\n",
      "nineteenth-century 1\n",
      "curious 1\n",
      "indescribable 1\n",
      "ecstasy 1\n",
      "aware 1\n",
      "intimate 1\n",
      "physical 1\n",
      "exo- 1\n",
      "tic 1\n",
      "universal 1\n",
      "nail 1\n",
      "anymore 1\n",
      "run- 1\n",
      "explode 1\n",
      "confident 1\n",
      "environ- 1\n",
      "separate 1\n",
      "distant 1\n",
      "skill 1\n",
      "expand- 1\n",
      "activate 1\n",
      "want 1\n",
      "good 1\n",
      "xorijiy 1\n"
     ]
    }
   ],
   "source": [
    "female_adjectives = []\n",
    "female_nouns = []\n",
    "\n",
    "for doi in female_dois: \n",
    "    path = os.path.join('Corpus_Japanese','TXT',f'{doi}_en.txt')\n",
    "    text = open(path,encoding='utf-8')\n",
    "    full_text = text.read()\n",
    "    words = word_tokenize(full_text.lower())\n",
    "    words = clean_wordlist(words)\n",
    "    \n",
    "    pos = pos_tag(words)\n",
    "\n",
    "    for p in pos:\n",
    "        if re.search( '^JJ',p[1] ):\n",
    "            female_adjectives.append(p[0])\n",
    "        if re.search( '^NN',p[1] ):\n",
    "            female_nouns.append(p[0])\n",
    "\n",
    "adj_freq_female = Counter(female_adjectives)\n",
    "for w,c in adj_freq_female.most_common():\n",
    "    print(w,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa176d",
   "metadata": {},
   "source": [
    "Which frequent adjectives from the articles on male authors are NEVER used in articles on female authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f5a1774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital 65\n",
      "universitas 64\n",
      "uchi 54\n",
      "qualitative 52\n",
      "disciplinary 52\n",
      "readable 42\n",
      "superego 42\n",
      "structural 41\n",
      "various 38\n",
      "dian 36\n",
      "sachiko 36\n",
      "respectful 36\n",
      "norwegian 32\n",
      "stylistic 28\n",
      "surakarta 28\n",
      "slow 22\n",
      "theatrical 18\n",
      "sonkeigo 18\n",
      "use 18\n",
      "sociolinguistic 18\n",
      "descript 18\n",
      "ive 18\n",
      "speech 18\n",
      "higher 18\n",
      "dominant 18\n",
      "untuk 18\n",
      "lingkungan 18\n",
      "ide 18\n",
      "scholar 18\n",
      "higashinojapanese 17\n",
      "daily 17\n",
      "psychoanalytic 16\n",
      "successful 15\n",
      "adapt 15\n",
      "cognitive 15\n",
      "accompany 14\n",
      "bildungsro 14\n",
      "maret 14\n",
      "maxim 14\n",
      "equivalent 14\n",
      "discursive 14\n",
      "accurate 14\n",
      "speaker 14\n",
      "permatasari 14\n",
      "legitimate 14\n",
      "uly 14\n",
      "electrum 14\n",
      "ahmad 14\n",
      "kinds 14\n",
      "descr 14\n",
      "referential 14\n",
      "significant 14\n",
      "pradopo 14\n",
      "experi 14\n",
      "reliant 14\n",
      "indivisible 14\n",
      "tengo 14\n",
      "father 14\n",
      "wardani 13\n",
      "usdacid 13\n",
      "dharma 13\n",
      "unruly 13\n",
      "ird 13\n",
      "judgment 13\n",
      "birth 13\n",
      "bird 13\n",
      "intensive 13\n",
      "undergone 13\n",
      "unnatural 13\n",
      "heal 13\n",
      "reinforcement 13\n",
      "french 13\n",
      "structural-marxist 13\n",
      "antonio 13\n",
      "civil 13\n",
      "economic 13\n",
      "psychological 12\n",
      "sympathy 11\n",
      "big 11\n",
      "udc 11\n",
      "olga 11\n",
      "spachil 11\n",
      "russian 11\n",
      "predominant 11\n",
      "en- 11\n",
      "musical 11\n",
      "em- 11\n",
      "che- 11\n",
      "metaphorical 11\n",
      "mundane 11\n",
      "uncle 11\n",
      "vanya 11\n",
      "intertext 11\n",
      "narra- 11\n",
      "conflict 11\n",
      "rudn 11\n",
      "litera- 11\n",
      "ov 11\n",
      "doubleday 11\n",
      "dark 10\n",
      "nc/40/legalcode498 10\n",
      "forth 9\n",
      "broken 9\n",
      "watched 9\n",
      "respond 9\n",
      "terrible 9\n",
      "cheerful 9\n",
      "drown 9\n",
      "living 9\n",
      "durban 9\n",
      "anxious 9\n",
      "frequency 9\n",
      "experience 9\n",
      "revised 9\n",
      "hypocritical 9\n",
      "livin 9\n",
      "idiomatic 9\n",
      "enrichment 9\n",
      "psychology 9\n",
      "putri 9\n",
      "vocational 9\n",
      "previous 9\n",
      "neurologia 9\n",
      "twogenreofjapanese 8\n",
      "jousukekuroiwa 8\n",
      "universityoffukui 8\n",
      "fukui910-8507 8\n",
      "thepurposeofthispaperistoclassifythegenreofmodernjapanese 8\n",
      "literaryworksusingcharacteristicfeaturesevaluatedbythewordvectorstheaccuracyof 8\n",
      "thewordvectorsareapplicableinthegenreprobleminmodern 8\n",
      "supportvectormachine 8\n",
      "ithasbeenassumedthatthereexistsadistributionhypothesisforthe 8\n",
      "thedistributionhypothesisstates\\wordsthatoccurinthesamecontext 8\n",
      "skip-grammodelandcbowmodeltheskip-grammodelpredictscontextwordsfromthe 8\n",
      "thanskip-grammodelwhenlargeamountsoftextaretrainedonthesemodels 8\n",
      "becausetheyare 8\n",
      "reduceddimensionalitycomparedtotheinputtedone-hotvectorrepresentationstherefore 8\n",
      "thisworkislicensedunderacreativecommonsattributionnoncommercial 8\n",
      "noderivatives40license 8\n",
      "vol14 8\n",
      "no2 8\n",
      "south 8\n",
      "touch 8\n",
      "art 7\n",
      "ajhal 7\n",
      "london 7\n",
      "fauziyati 7\n",
      "ana 7\n",
      "urakami 7\n",
      "representative 7\n",
      "scie 7\n",
      "ntific 7\n",
      "syntactic 7\n",
      "introductory 7\n",
      "point 7\n",
      "uag 7\n",
      "commentary 6\n",
      "perspective 6\n",
      "mishima 6\n",
      "tetrad 6\n",
      "uma 6\n",
      "emptiness 6\n",
      "secret 5\n",
      "strong 5\n",
      "interpersonal 5\n",
      "normal 5\n",
      "harbin 5\n",
      "act 4\n",
      "latest 4\n",
      "individual 4\n",
      "triad 4\n",
      "detailed 4\n",
      "unable 4\n",
      "seek 4\n",
      "thin 4\n",
      "woman79 4\n",
      "pragmatic 3\n",
      "http 3\n",
      "commitment 3\n",
      "chronic 3\n",
      "takashi 3\n",
      "email 3\n",
      "muto 3\n",
      "postmodern 3\n",
      "poole 3\n",
      "broad 3\n",
      "intertwined 3\n",
      "residue 3\n",
      "intact 3\n",
      "don™t 3\n",
      "it™s 3\n",
      "attempt 3\n",
      "a-z 3\n",
      "psychoanalytical 3\n",
      "american 3\n",
      "intellect 3\n",
      "//doiorg/101590/0004-282x-anp-2021-0373 3\n",
      "neurocirurgia 3\n",
      "endovascular 3\n",
      "//orcidorg/0000-0003-1166-9722 3\n",
      "abm 3\n",
      "//orcidorg/0000-0003-3926-3951 3\n",
      "author™s 3\n",
      "mkf 3\n",
      "˚nal 3\n",
      "likely 3\n",
      "sound 3\n",
      "episodic 3\n",
      "compatible 3\n",
      "mild 3\n",
      "apraxia 3\n",
      "initial 3\n",
      "disease 3\n",
      "neurological 3\n",
      "medicine 3\n",
      "umoo 3\n",
      "sempre 3\n",
      "que 3\n",
      "escreveram 3\n",
      "shingo 3\n",
      "apenas 3\n",
      "outro 3\n",
      "novo 3\n",
      "usando 3\n",
      "nos 3\n",
      "desa˚os 3\n",
      "neurológicos 3\n",
      "palavras-chave 3\n",
      "introductio 3\n",
      "n˜e 3\n",
      "demographic 3\n",
      "last 3\n",
      "popu 3\n",
      "excess 3\n",
      "total 3\n",
      "impact 3\n",
      "di˚erent 3\n",
      "recurrent 3\n",
      "theme 3\n",
      "religious 3\n",
      "shinto 3\n",
      "venerable 3\n",
      "idealised 3\n",
      "quasi-mystical 3\n",
      "-ary 3\n",
      "yotsugi 3\n",
      "anonymous 3\n",
      "okagami 3\n",
      "-lar 3\n",
      "rapid 3\n",
      "cynical 3\n",
      "youth 3\n",
      "manga 3\n",
      "storyline 3\n",
      "former 3\n",
      "sun 3\n",
      "lose 3\n",
      "wrong 3\n",
      "wind-up 3\n",
      "//instancemetastoreingentacom/content/journals/101386/eapc_00041_1 2\n",
      "john 2\n",
      "african 2\n",
      "content 2\n",
      "psychopathy 2\n",
      "behavior 2\n",
      "tanizaki™s 2\n",
      "utsugi330https 2\n",
      "regard 2\n",
      "organic 2\n",
      "rebuild 2\n",
      "appreciate 2\n",
      "barrier 2\n",
      "fundamental 2\n",
      "extract 2\n",
      "secondary 2\n",
      "feel 2\n",
      "change 2\n",
      "questionnaire 2\n",
      "resonate 2\n",
      "fan 2\n",
      "suitable 2\n",
      "fit 2\n",
      "intelligent 2\n",
      "temperament 2\n",
      "ibid 2\n",
      "hayao 2\n",
      "hurt 2\n",
      "naoko 2\n",
      "limited 2\n",
      "smile 2\n",
      "worth 2\n",
      "shincho 2\n",
      "eighth 2\n",
      "above-mentioned 2\n",
      "shanghai 2\n",
      "inner 2\n",
      "connect 2\n",
      "bunko 2\n",
      "kindle 2\n",
      "editorial 2\n",
      "e-mail 2\n",
      "scientific 2\n",
      "intr 1\n",
      "search 1\n",
      "welcome 1\n",
      "user 1\n",
      "guide 1\n",
      "librarian 1\n",
      "subscribe 1\n",
      "faqs 1\n",
      "citation_alert 1\n",
      "correction_alert 1\n",
      "mendeley 1\n",
      "e-issn 1\n",
      "boman1 1\n",
      "stockholm 1\n",
      "doi 1\n",
      "table 1\n",
      "full-text 1\n",
      "quantitative 1\n",
      "lexical 1\n",
      "tandem 1\n",
      "well-known 1\n",
      "/content/journals/101386/eapc_00041_1 1\n",
      "theresa 1\n",
      "inter-rater 1\n",
      "empirical 1\n",
      "shigehiro 1\n",
      "lawrence 1\n",
      "korean 1\n",
      "hosker-field 1\n",
      "ashley 1\n",
      "thematic 1\n",
      "brunswick 1\n",
      "cinema 1\n",
      "uzoma 1\n",
      "tim 1\n",
      "kautz 1\n",
      "myth 1\n",
      "achievement 1\n",
      "naoki 1\n",
      "trait 1\n",
      "measurement 1\n",
      "theoretical 1\n",
      "vol 1\n",
      "norman 1\n",
      "sarotoru 1\n",
      "shite 1\n",
      "sartrean 1\n",
      "existential 1\n",
      "kochhar-lindgren 1\n",
      "gray 1\n",
      "lacan 1\n",
      "norton 1\n",
      "chang-dong 1\n",
      "uursula 1\n",
      "conrad 1\n",
      "forbidden 1\n",
      "google 1\n",
      "kinkaku-ji 1\n",
      "golden 1\n",
      "napier 1\n",
      "susan 1\n",
      "ten-item 1\n",
      "nefertiti 1\n",
      "dickinson 1\n",
      "taxonomy 1\n",
      "phallic 1\n",
      "anal 1\n",
      "oral 1\n",
      "terrorist 1\n",
      "intellectual 1\n",
      "kolar 1\n",
      "darkness 1\n",
      "grant 1\n",
      "leary 1\n",
      "herbert 1\n",
      "impasse 1\n",
      "therapeutic 1\n",
      "anti-therapeutic 1\n",
      "psychotic 1\n",
      "neurotic 1\n",
      "ueda 1\n",
      "nature 1\n",
      "doreen 1\n",
      "vivian 1\n",
      "predictor 1\n",
      "specific 1\n",
      "two-layer 1\n",
      "behavioural 1\n",
      "kawaii 1\n",
      "agentic 1\n",
      "paul 1\n",
      "lovable 1\n",
      "affect 1\n",
      "shōjo- 1\n",
      "shōnen-manga 1\n",
      "unser-schutz 1\n",
      "transnational 1\n",
      "neutral 1\n",
      "cheuk-yin 1\n",
      "k-pop 1\n",
      "whisky 1\n",
      "nhk 1\n",
      "timo 1\n",
      "recommend 1\n",
      "-contenttype 1\n",
      "up-to-date 1\n",
      "teamcontact 1\n",
      "ussubscribe 1\n",
      "useprivacy 1\n",
      "journalsa-z 1\n",
      "publish 1\n",
      "uslatest 1\n",
      "subscribelibrarian 1\n",
      "required 1\n",
      "valid 1\n",
      "invalid 1\n",
      "released 1\n",
      "pre-order 1\n",
      "no4 1\n",
      "shinjuku-ku 1\n",
      "simple 1\n",
      "村上春樹 1\n",
      "active 1\n",
      "cite 1\n",
      "subcultural 1\n",
      "module 1\n",
      "before4 1\n",
      "shaohua 1\n",
      "beijing 1\n",
      "refer 1\n",
      "reflect 1\n",
      "analyze 1\n",
      "patient 1\n",
      "grasp 1\n",
      "mental 1\n",
      "temporary 1\n",
      "softbank 1\n",
      "本田秀夫『自閉症スペクトラム』ソフトバンク新書 1\n",
      "severe 1\n",
      "difficulty 1\n",
      "asperger 1\n",
      "psychiatric 1\n",
      "column 1\n",
      "necessary 1\n",
      "painful 1\n",
      "married 1\n",
      "twenty-two 1\n",
      "love 1\n",
      "autistic 1\n",
      "self-healing 1\n",
      "tiny 1\n",
      "tentative 1\n",
      "『風の歌を聴け』 1\n",
      "conscious 1\n",
      "accustomed 1\n",
      "ate 1\n",
      "sad 1\n",
      "mad 1\n",
      "excited 1\n",
      "specialized-machine-tool 1\n",
      "ill 1\n",
      "rid 1\n",
      "lonely 1\n",
      "upset 1\n",
      "dance 1\n",
      "senno 1\n",
      "regarding 1\n",
      "characteristic 1\n",
      "twelve-year-old 1\n",
      "radiant 1\n",
      "hear 1\n",
      "help 1\n",
      "end 1\n",
      "decisive 1\n",
      "healed 1\n",
      "novelist 1\n",
      "contrary 1\n",
      "yoichi 1\n",
      "study-a 1\n",
      "asia8 1\n",
      "third 1\n",
      "fourth 1\n",
      "kong 1\n",
      "depth 1\n",
      "atmosphere 1\n",
      "purpose 1\n",
      "close 1\n",
      "pleased 1\n",
      "afraid 1\n",
      "determined 1\n",
      "calm 1\n",
      "imply 1\n",
      "inevitable 1\n",
      "fierce 1\n",
      "independent 1\n",
      "strange 1\n",
      "empty 1\n",
      "novels 1\n",
      "armrest 1\n",
      "xun 1\n",
      "honest 1\n",
      "listen 1\n",
      "guilty 1\n",
      "monologue 1\n",
      "peek 1\n",
      "irrelevant 1\n",
      "hypothetical 1\n",
      "assume 1\n",
      "lobata 1\n",
      "sugiyama 1\n",
      "invest 1\n",
      "expect 1\n",
      "sacred 1\n",
      "communicate 1\n",
      "chat 1\n",
      "yan 1\n",
      "大江健三郎 1\n",
      "nobel 1\n",
      "manovich 1\n",
      "postmodern–japanese 1\n",
      "otaku 1\n",
      "element 1\n",
      "incurable 1\n",
      "takumasa 1\n",
      "half 1\n",
      "20th 1\n",
      "answered 1\n",
      "ranked 1\n",
      "second-placed 1\n",
      "incomplete 1\n",
      "front 1\n",
      "girlfriend 1\n",
      "shimamoto-the 1\n",
      "swallow 1\n",
      "asia 1\n",
      "fifth 1\n",
      "figure 1\n",
      "東浩紀 1\n",
      "postmodern—japanese 1\n",
      "動物化するポストモダン-オタクから見た日本社会 1\n",
      "mit 1\n",
      "風の歌を聴け 1\n",
      "杉山康彦 1\n",
      "whatsapp 1\n",
      "related 1\n",
      "select 1\n",
      "aast 1\n",
      "abb 1\n",
      "adr 1\n",
      "ajor 1\n",
      "ampc 1\n",
      "asm 1\n",
      "ijmnta 1\n",
      "mrc 1\n",
      "njgc 1\n",
      "ojapo 1\n",
      "ojd 1\n",
      "ojgas 1\n",
      "ojmetal 1\n",
      "ojo 1\n",
      "ojopm 1\n",
      "ojpm 1\n",
      "ojpp 1\n",
      "ojtr 1\n",
      "soft 1\n",
      "uoaj 1\n",
      "faq 1\n"
     ]
    }
   ],
   "source": [
    "for word,count in adj_freq_male.most_common():\n",
    "    if word not in adj_freq_female.keys():\n",
    "        print(word , count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd48de9",
   "metadata": {},
   "source": [
    "Which frequent adjectives from the articles on female authors are NEVER used in articles on male authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c0d77d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tale 166\n",
      "tamenori 64\n",
      "classic 40\n",
      "mama 36\n",
      "complex 35\n",
      "prose 35\n",
      "heian 33\n",
      "entire 33\n",
      "dystopian 32\n",
      "exemplum 32\n",
      "seventeenth- 32\n",
      "eighteenth- 32\n",
      "lady-in-waiting 32\n",
      "empress 32\n",
      "syllabic 32\n",
      "ﬁwoman™s 32\n",
      "discussed 32\n",
      "exclusive 32\n",
      "murasaki™s 32\n",
      "generic 32\n",
      "highest 32\n",
      "edward 32\n",
      "center 32\n",
      "michigan 32\n",
      "hotaru 32\n",
      "tamakazura 32\n",
      "tyler 32\n",
      "=2- 30\n",
      "a-d 30\n",
      "e+/0 30\n",
      "0-e+ 30\n",
      "l-m- 30\n",
      "nc=c1co+ 30\n",
      "e-2 30\n",
      ":42rsr 30\n",
      "t-3+ 30\n",
      "feminist 29\n",
      "emissary 24\n",
      "environmental 24\n",
      "apocalyptic 24\n",
      "genji 19\n",
      "write 18\n",
      "sosial 18\n",
      "ukuran 18\n",
      "february 17\n",
      "domestic 16\n",
      "philosophical 16\n",
      "financial 15\n",
      "national 14\n",
      "public 14\n",
      "aniqua 14\n",
      "munawar 14\n",
      "chaudhary 14\n",
      "dime 14\n",
      "workforce 14\n",
      "invidious 14\n",
      "patriarchal 14\n",
      "strait 14\n",
      "eggs 14\n",
      "unveil 14\n",
      "embodiment 14\n",
      "faith 14\n",
      "quest 14\n",
      "authentic 14\n",
      "obtainable 14\n",
      "small 13\n",
      "//ijlcwumedupk/indexphp/ojsinternational 13\n",
      "™smemoirsofapolarbear 13\n",
      "pennyyeungisaphdcandidateincom- 13\n",
      "translationstudiesinmultilingual 13\n",
      "memoirsofapolar 13\n",
      "thesepassagesfromthebook 13\n",
      "ienteredthestorybeingtoldasitspro- 13\n",
      "boldpro- 13\n",
      "nouncementswescarcelythinkofaspropertothememoir 13\n",
      "memoirsofapolarbear 13\n",
      "novelisticlifeoftheirown 13\n",
      "theyannouncethepreferredcompositionalstrategiesoftheprotag- 13\n",
      "andwhoistryingtoresolvethe 13\n",
      "linguisticconundrumarisingfromhermigrationacrossgeographic 13\n",
      "writingmylifeinseverallanguagesatthesametime 13\n",
      "notonlythepolarbear 13\n",
      "™sauthorhasbeen 13\n",
      "addressinginhervastbodyofworktawada 13\n",
      "whomovedto 13\n",
      "germanyfromjapanin1982atagetwenty-two 13\n",
      "hasdrawnanenor- 13\n",
      "mouscreativeenergyfromwhatthebear-protagonistpresentsasa 13\n",
      "ﬁbeinganovelistitwouldbemucheasier 13\n",
      "massive 10\n",
      "e-journal 10\n",
      "d14/ 10\n",
      "g4- 10\n",
      "l2- 10\n",
      "s27 10\n",
      "w4-4 10\n",
      "uzbek 10\n",
      "ushbu 10\n",
      "cbcf6f6f6dcg 10\n",
      "8-/h 10\n",
      "8-i 10\n",
      "+0i03- 10\n",
      "m8- 10\n",
      "-0= 10\n",
      ",8+a= 10\n",
      "p/3- 10\n",
      "/-a 10\n",
      "ancient 9\n",
      "great 9\n",
      "xian 9\n",
      "pebruari 9\n",
      "anuary 9\n",
      "ari 9\n",
      "sulatri 9\n",
      "budaya 9\n",
      "analyzed 9\n",
      "wellek 9\n",
      "goodman 9\n",
      "ideal 9\n",
      "honne 9\n",
      "foun 9\n",
      "lifestyle 9\n",
      "tomo 9\n",
      "deskriptif 9\n",
      "sastra 9\n",
      "karakteristik 9\n",
      "dan 9\n",
      "berdasarkan 9\n",
      "kelompok 9\n",
      "ditemukan 9\n",
      "ibuki 9\n",
      "arisa 9\n",
      "little 8\n",
      "suematsu 8\n",
      "literaria 8\n",
      "interdisciplinary 8\n",
      "january 8\n",
      "seng 8\n",
      "irreparable 8\n",
      "glimpse 8\n",
      "cial 8\n",
      "delic 8\n",
      "inhabitable 8\n",
      "strict 8\n",
      "yoshiro 8\n",
      "mumei 8\n",
      "futuristic 8\n",
      "dysfunctional 8\n",
      "regressive 8\n",
      "unknown 8\n",
      "rural 8\n",
      "nagano 8\n",
      "uninhabitable 8\n",
      "multiple 8\n",
      "pernicious 8\n",
      "lengthy 8\n",
      "single 7\n",
      "native 7\n",
      "novelistic 6\n",
      "read 5\n",
      "classical 5\n",
      "poem 5\n",
      "con- 5\n",
      "naira 5\n",
      "april 5\n",
      "prestigious 5\n",
      "iterary 5\n",
      "reveal 5\n",
      "obrazi 5\n",
      "zlar 5\n",
      "mentaliteti 5\n",
      "bosh 5\n",
      "ishlangan 5\n",
      "roman 5\n",
      "ulardan 5\n",
      "nufuzli 5\n",
      "bir 5\n",
      "teacher 5\n",
      "phonetic 4\n",
      "realm 4\n",
      "extraordinary 4\n",
      "affordable 4\n",
      "impossible 4\n",
      "know 4\n",
      "brazilian 3\n",
      "recent 3\n",
      "parallel 3\n",
      "nineteenth 3\n",
      "typographical 3\n",
      "easier 3\n",
      "influential 3\n",
      "global 3\n",
      "peculiar 3\n",
      "larger 3\n",
      "waley 3\n",
      "tanizaki 3\n",
      "critical 3\n",
      "symbolic 3\n",
      "see 3\n",
      "naked 3\n",
      "dialect 3\n",
      "title 2\n",
      "cannibal 2\n",
      "andrade 2\n",
      "comprehensive 2\n",
      "commercial 2\n",
      "readership 2\n",
      "subsequent 2\n",
      "elite 2\n",
      "hiragana 2\n",
      "essential 2\n",
      "discrete 2\n",
      "semantic 2\n",
      "shakespeare 2\n",
      "unequal 2\n",
      "large 2\n",
      "enormous 2\n",
      "powerful 2\n",
      "poor 2\n",
      "british 2\n",
      "appetite 2\n",
      "reasonable 2\n",
      "wealthy 2\n",
      "accessible 2\n",
      "definitive 2\n",
      "lit- 2\n",
      "thirty 2\n",
      "lished 2\n",
      "triple 2\n",
      "perceive 2\n",
      "future 2\n",
      "portable 2\n",
      "heterosexual 2\n",
      "side 2\n",
      "die 2\n",
      "clean 2\n",
      "under- 2\n",
      "fantasy 2\n",
      "magic 2\n",
      "serious 2\n",
      "sensual 2\n",
      "anglophone 1\n",
      "script 1\n",
      "brazil 1\n",
      "portuguese 1\n",
      "potential 1\n",
      "enemy 1\n",
      "nourish 1\n",
      "incorporating—admirable 1\n",
      "dietary 1\n",
      "figurative 1\n",
      "williams 1\n",
      "anglo-european 1\n",
      "seventy 1\n",
      "release 1\n",
      "oscar-winning 1\n",
      "lambs 1\n",
      "man-eating 1\n",
      "protégé 1\n",
      "martial 1\n",
      "shikibu1 1\n",
      "puzzle 1\n",
      "interregional 1\n",
      "geographic 1\n",
      "diachronic 1\n",
      "rowley 1\n",
      "industrial 1\n",
      "employed 1\n",
      "artistic 1\n",
      "scholarship 1\n",
      "relevant 1\n",
      "situate 1\n",
      "regional 1\n",
      "nourishment 1\n",
      "buddhist 1\n",
      "sought 1\n",
      "archipelago 1\n",
      "spent 1\n",
      "life—which 1\n",
      "imperial 1\n",
      "spoken 1\n",
      "usage 1\n",
      "hiragana-type 1\n",
      "immediate 1\n",
      "distribute 1\n",
      "truthfulness 1\n",
      "thirteenth 1\n",
      "ancestral 1\n",
      "employ 1\n",
      "amongst 1\n",
      "premodern 1\n",
      "foundational 1\n",
      "notion 1\n",
      "shift 1\n",
      "david 1\n",
      "ninth 1\n",
      "distinct 1\n",
      "questioned 1\n",
      "undervalue 1\n",
      "fevered 1\n",
      "territorial 1\n",
      "indebtedness 1\n",
      "attempted 1\n",
      "depict 1\n",
      "diary 1\n",
      "teach 1\n",
      "sutra 1\n",
      "playful 1\n",
      "allusion 1\n",
      "myriad 1\n",
      "scripts 1\n",
      "latin 1\n",
      "similarly 1\n",
      "untranslated 1\n",
      "deceptive 1\n",
      "tidy 1\n",
      "narration 1\n",
      "insertion 1\n",
      "typographic 1\n",
      "millennium-old 1\n",
      "400-year-old 1\n",
      "genji—which 1\n",
      "plot 1\n",
      "shakespearian 1\n",
      "incredible 1\n",
      "conversant 1\n",
      "shōyō 1\n",
      "must-read 1\n",
      "plentiful 1\n",
      "unreadable 1\n",
      "didactic 1\n",
      "antecedent 1\n",
      "advanced 1\n",
      "xiao 1\n",
      "customary 1\n",
      "tsubouchi 1\n",
      "fujioka 1\n",
      "kokubungaku 1\n",
      "greatest 1\n",
      "acclaim 1\n",
      "commentarial 1\n",
      "vibrant 1\n",
      "japaneseness 1\n",
      "argue 1\n",
      "cohesive 1\n",
      "quasi-isolationist 1\n",
      "penchant 1\n",
      "britain 1\n",
      "unfair 1\n",
      "universe 1\n",
      "driven 1\n",
      "principal 1\n",
      "give 1\n",
      "strive 1\n",
      "equal 1\n",
      "known 1\n",
      "contact 1\n",
      "opportune 1\n",
      "vertical 1\n",
      "standardized 1\n",
      "reviewer 1\n",
      "spectator 1\n",
      "tedious 1\n",
      "conservative 1\n",
      "caddeau 1\n",
      "tokugawa 1\n",
      "partial 1\n",
      "negative 1\n",
      "lambasted 1\n",
      "meaningless 1\n",
      "well-regarded 1\n",
      "movable 1\n",
      "influenced 1\n",
      "undertaken 1\n",
      "oriental 1\n",
      "masterful 1\n",
      "joyce 1\n",
      "become 1\n",
      "akin 1\n",
      "sukehiro 1\n",
      "colonized 1\n",
      "subvert 1\n",
      "supremacy 1\n",
      "european 1\n",
      "extensive 1\n",
      "america 1\n",
      "enjoy 1\n",
      "38-volume 1\n",
      "translation 1\n",
      "sekai 1\n",
      "dynic 1\n",
      "nagamine 1\n",
      "par 1\n",
      "yūsaku 1\n",
      "notice 1\n",
      "saw 1\n",
      "friend 1\n",
      "novelist-turned-translator 1\n",
      "catapulted 1\n",
      "shikibu 1\n",
      "subscription 1\n",
      "promotional 1\n",
      "haul 1\n",
      "launch 1\n",
      "meet 1\n",
      "empty-handed 1\n",
      "hybrid 1\n",
      "largest 1\n",
      "bold 1\n",
      "perform 1\n",
      "critic 1\n",
      "fortunate 1\n",
      "misunderstood 1\n",
      "perennial 1\n",
      "japanese—remain 1\n",
      "bastion 1\n",
      "draw 1\n",
      "millennium 1\n",
      "shifts 1\n",
      "reverse-importation8 1\n",
      "describe 1\n",
      "helpful 1\n",
      "follow-up 1\n",
      "and—while 1\n",
      "underpin 1\n",
      "multi-sectored 1\n",
      "sushi 1\n",
      "genji-inspired 1\n",
      "ritz-carlton 1\n",
      "vis-à-vis 1\n",
      "enriched 1\n",
      "erary 1\n",
      "guest 1\n",
      "pub- 1\n",
      "united 1\n",
      "excerpt 1\n",
      "tsunami 1\n",
      "nuclear 1\n",
      "narrate 1\n",
      "bigger 1\n",
      "memory 1\n",
      "par- 1\n",
      "ticular 1\n",
      "relation- 1\n",
      "func- 1\n",
      "audio 1\n",
      "ring- 1\n",
      "one-woman 1\n",
      "passage 1\n",
      "continuous 1\n",
      "happen 1\n",
      "obvious 1\n",
      "cata- 1\n",
      "strophic 1\n",
      "primary 1\n",
      "extreme 1\n",
      "phys- 1\n",
      "some- 1\n",
      "material 1\n",
      "left 1\n",
      "hav- 1\n",
      "logic 1\n",
      "subconscious 1\n",
      "tend 1\n",
      "explosive 1\n",
      "etc 1\n",
      "brim 1\n",
      "younger 1\n",
      "take-off 1\n",
      "speak 1\n",
      "spend 1\n",
      "poet 1\n",
      "step- 1\n",
      "feels 1\n",
      "nected 1\n",
      "come 1\n",
      "conventional 1\n",
      "alive 1\n",
      "endless 1\n",
      "hap- 1\n",
      "crazy 1\n",
      "colour 1\n",
      "exceptional 1\n",
      "illuminated 1\n",
      "paradoxical 1\n",
      "absurd 1\n",
      "clear-cut 1\n",
      "sentō 1\n",
      "pee 1\n",
      "lat- 1\n",
      "conceptual 1\n",
      "stem 1\n",
      "mean- 1\n",
      "visible 1\n",
      "foot 1\n",
      "thinking 1\n",
      "interesting 1\n",
      "landscape 1\n",
      "newborn 1\n",
      "fashionable 1\n",
      "super 1\n",
      "extra 1\n",
      "dirty 1\n",
      "dirt 1\n",
      "used 1\n",
      "sucked 1\n",
      "dead 1\n",
      "skin 1\n",
      "tub 1\n",
      "happy 1\n",
      "head 1\n",
      "told 1\n",
      "terrified 1\n",
      "grand- 1\n",
      "understood 1\n",
      "per- 1\n",
      "pres- 1\n",
      "easy 1\n",
      "outspoken 1\n",
      "rep- 1\n",
      "resent 1\n",
      "messy 1\n",
      "ask 1\n",
      "oppressive 1\n",
      "encour- 1\n",
      "call 1\n",
      "backlash 1\n",
      "thought 1\n",
      "discrimi- 1\n",
      "injustice 1\n",
      "care 1\n",
      "book-length 1\n",
      "rare 1\n",
      "joint 1\n",
      "favorite 1\n",
      "essay 1\n",
      "harakiri 1\n",
      "eccentric 1\n",
      "neighbours 1\n",
      "epoch-making 1\n",
      "influ- 1\n",
      "chal- 1\n",
      "imaginative 1\n",
      "fable 1\n",
      "ladder 1\n",
      "inside 1\n",
      "survive 1\n",
      "metaphysical 1\n",
      "orig- 1\n",
      "inal 1\n",
      "yur- 1\n",
      "iko 1\n",
      "ninjō 1\n",
      "child 1\n",
      "middle-aged 1\n",
      "stereotype 1\n",
      "actual 1\n",
      "comedic 1\n",
      "double 1\n",
      "funny 1\n",
      "straight-man 1\n",
      "sidekick 1\n",
      "nori-tsukomi 1\n",
      "one-man 1\n",
      "formed 1\n",
      "collo- 1\n",
      "quial 1\n",
      "silent 1\n",
      "differ- 1\n",
      "aloud 1\n",
      "simul- 1\n",
      "ver- 1\n",
      "dialogue 1\n",
      "standard 1\n",
      "turn 1\n",
      "nineteenth-century 1\n",
      "curious 1\n",
      "indescribable 1\n",
      "ecstasy 1\n",
      "aware 1\n",
      "intimate 1\n",
      "exo- 1\n",
      "universal 1\n",
      "nail 1\n",
      "anymore 1\n",
      "run- 1\n",
      "explode 1\n",
      "confident 1\n",
      "environ- 1\n",
      "distant 1\n",
      "skill 1\n",
      "expand- 1\n",
      "activate 1\n",
      "want 1\n",
      "xorijiy 1\n"
     ]
    }
   ],
   "source": [
    "for word,count in adj_freq_female.most_common():\n",
    "    if word not in adj_freq_male.keys():\n",
    "        print(word , count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172bf32",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e840870",
   "metadata": {},
   "source": [
    "The cell outputs sentences in the articles on male authors which have a sentiment score of less than -0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7106c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "nr_sentences = 0\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "male_sentences = dict()\n",
    "\n",
    "for doi in male_dois: \n",
    "    path = os.path.join('Corpus_Japanese','TXT',f'{doi}_en.txt')\n",
    "    text = open(path,encoding='utf-8')\n",
    "    full_text = text.read()\n",
    "    sentences = sent_tokenize(full_text)\n",
    "    for sentence in sentences:\n",
    "        scores = ana.polarity_scores(sentence)\n",
    "        nr_sentences += 1\n",
    "        if scores['compound'] > 0.5:\n",
    "            count_positive+=1\n",
    "        elif scores['compound'] < -0.5:\n",
    "            count_negative+=1\n",
    "        male_sentences[sentence] = scores['compound']\n",
    "        \n",
    "\n",
    "count_neutral = nr_sentences - count_positive-count_negative\n",
    "\n",
    "data.append( ['Male',count_neutral/nr_sentences,count_positive/nr_sentences,count_negative/nr_sentences] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4597cd51",
   "metadata": {},
   "source": [
    "The cell outputs sentences in the articles on female authors which have a sentiment score of less than -0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4c68c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_sentences = 0\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "female_sentences = dict()\n",
    "\n",
    "for doi in female_dois: \n",
    "    path = os.path.join('Corpus_Japanese','TXT',f'{doi}_en.txt')\n",
    "    text = open(path,encoding='utf-8')\n",
    "    full_text = text.read()\n",
    "    sentences = sent_tokenize(full_text)\n",
    "    for sentence in sentences:\n",
    "        scores = ana.polarity_scores(sentence)\n",
    "        nr_sentences += 1\n",
    "        if scores['compound'] > 0.5:\n",
    "            count_positive+=1\n",
    "        elif scores['compound'] < -0.5:\n",
    "            count_negative+=1\n",
    "            female_sentences[sentence] = scores['compound']\n",
    "        \n",
    "\n",
    "count_neutral = nr_sentences - count_positive-count_negative\n",
    "\n",
    "data.append( ['Female',count_neutral/nr_sentences,count_positive/nr_sentences,count_negative/nr_sentences] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "22d1e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data,columns=['gender','neutral','positive','negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e4b350a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "y_axis = 'gender'\n",
    "\n",
    "fig = plt.figure( figsize=( 8 , 5 ) )\n",
    "\n",
    "df['combined'] = df['positive'] + df['neutral'] + df['negative']\n",
    "graph = sns.barplot( data=df , x='combined', y=y_axis , label = 'Negative', color = '#c90e0e' )\n",
    "df['combined'] = df['combined'] - df['negative']\n",
    "graph = sns.barplot( data=df , x='combined', y=y_axis , color = '#ebdfdf')\n",
    "df['combined'] = df['combined'] - df['neutral']\n",
    "graph = sns.barplot( data=df , x='combined', y=y_axis , label = 'Positive' ,color = '#1b66de')\n",
    "\n",
    "graph.set_title('Sentiment analysis' , size = 20) \n",
    "graph.set_xlabel('Scores' , size = 14) \n",
    "graph.set_ylabel('Gender' , size = 14 )\n",
    "\n",
    "plt.xticks(rotation= 90)\n",
    "\n",
    "# The next line places the legend outside out the plot\n",
    "plt.legend( bbox_to_anchor=(1.05, 1),loc=2, borderaxespad=0.);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f63bd1a",
   "metadata": {},
   "source": [
    "### Most negative sentence in articles on male authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a5472250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sense of Loneliness, Blockage, and Emptiness in Haruki Murakami’s Works\n",
      "When we discuss the problems of the sense of loneliness, blockage, and emptiness in Haruki Murakami’s works, we must first understand the characteristics of these feelings described by him.\n",
      "-0.9201\n",
      "Excessive fear or anxiety can make a person drown in his bad imagination, sometimes it prevents him from living life that goes on (Durban, J.\n",
      "-0.8957\n",
      "…\n",
      "I may be defeated, or I may be lost, or I may not be able to reach anywhere, or perhaps everything has been destroyed irretrievably no matter how hard I tried.\n",
      "-0.8391\n",
      "Currently, anxiety disorders affect more than 8.4 million people in the world and about 6.6 million people experience depression which is preceded by an anxiety disorder.\n",
      "-0.8316\n",
      "The sense of loneliness described by Haruki Murakami is nothing more than the suffering of people who are not good at interpersonal relationships and cannot get used to the society.\n",
      "-0.821\n",
      "And they almost have the tendency of autism spectrum, that is, loneliness belonging to social deficit, communication deficit, and rigidity or restricted interest.\n",
      "-0.8176\n",
      "Resonance with the Sense of Loneliness, Blockage, and Emptiness\n",
      "Let us first look at the example of social deficit.\n",
      "-0.8126\n",
      "There are always stories of sadness and suffering in life that are experienced both physically and mentally, to respond to this a human being can choose to show his suffering to the world to get sympathy or cover it up and play the role of someone else as if the suffering was never present in his life.\n",
      "-0.8074\n",
      "This story will be related to today's era, reflecting social criticism with the surrounding influences that make the most hypocritical livin g beings and easily lead to bad things.\n",
      "-0.807\n",
      "I didn’t feel hurt or sad.\n",
      "-0.7579\n",
      "I ate alone, took walks alone, went swimming alone, and went to concerts and movies alone.\n",
      "-0.7184\n",
      "This may be because Murakami’s works do not simply remind the despair of today’s society, but describe the suffering of modern people who cannot adapt to society and cannot simply find a way out.\n",
      "-0.7003\n",
      "They resonate with the sense of loneliness, blockage, and emptiness of the work.\n",
      "-0.6908\n",
      "However, in the questionnaire surveys and interviews I conducted in various cities, when I asked “Which parts of Haruki Murakami do you like?”, the most common responses from almost all cities were “resonate with the loneliness of the characters in the work” and “resonate with the sense of emptiness of the work”6.\n",
      "-0.6908\n",
      "The mood of young readers in East Asian cities (feeling of loneliness, blockage, emptiness, barrier to society, etc.)\n",
      "-0.6908\n"
     ]
    }
   ],
   "source": [
    "import tm\n",
    "\n",
    "\n",
    "for i,sentence in enumerate(tm.sorted_by_value(male_sentences)):\n",
    "    if i< 15:\n",
    "        print(f\"{sentence}\\n{male_sentences[sentence]}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc370f6",
   "metadata": {},
   "source": [
    "### Most negative sentence in articles on female authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7a94593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I was little, I used to be so scared of the drain that sucked up all the hair and dead skin.\n",
      "-0.9009\n",
      "Due to environmental degeneration, the dystopian Japanese society is ostensibly suffering from contaminations, extinctions and overpopulation of elderly, while the children, ironically, are born frail, sick and delic the two main protagonists, Yoshiro and Mumei in the inhabitable, post - apocalyptic Japanese society.\n",
      "-0.8957\n",
      "The Kafkaesque depiction of t he regressive post - apocalyptic Japanese dystopian society in the novella further reimagines Keywords : Dystopian , Post - Apocalyptic , Environmental Degeneration , Environmental Adaptation , Japanese Literature .\n",
      "-0.8689\n",
      "It’s all paradoxical and absurd, but no one is going to live or die in your place.\n",
      "-0.8462\n",
      "As the Japanese government imposes a strict isolation policy, it captures how both Yoshiro and Mumei cope and react with the perils that the disaster imposes.\n",
      "-0.8225\n",
      "I wasn’t in the disaster zone, but I heard about how the cell phones of people who had gone missing would keep ring- ing and ringing, even though no one was there to answer them.\n",
      "-0.7992\n",
      "The novella further satirizes the futuristic Japanese society by envisioning a distressing dysfunctional society that predominantly deals with the aftermath of the catastrophe.\n",
      "-0.7964\n",
      "You can be social and party like crazy, but we all die alone.\n",
      "-0.7876\n",
      "Keywords: Feminist existentialism; Alienation; Embodiment; Authenticity; Mieko Kawakami; Women's writing; Capitalism Volume & Issues Obtainable at The Women University Multan International Journal of Linguistics and Culture ISSN (P): 2707 - 6873, ISSN (O): 2788 - 8347 Volume 3, No 2 , December 2022 Journal homepage: http://ijlc.wum.edu.pk/index.php/ojsInternational Journal of Linguistics and Culture ISSN(P) 2707 - 6873 Volume 03, No 0 2 , December 202 2 179 Alienation, Embodiment, and Search for Authenticity Breasts and Eggs Aniqua Munawar PhD Scholar , Department of English, Bahauddin Zakariya University, Multan Fariha Chaudhary Assistant P rofessor, Department of English, Bahauddin Zakariya University, Multan.\n",
      "-0.765\n",
      "But we’re also born into this world and we die, and that experience is universal.\n",
      "-0.7469\n",
      "Arguments evincing the purity of Japaneseness were raised to a fevered pitch during the Second World War, when cultural chauvinism and territorial expansion motivated some Japanese scholars to deny Murasaki’s cultural indebtedness to China.\n",
      "-0.7184\n",
      "The problems we face in this world, the pain we experience — these can be put into words and passed on to the next generation.\n",
      "-0.7184\n",
      "We’re not here to win an argument.\n",
      "-0.678\n",
      "Meiji era Japanese were viewed by Western leaders as inferior and thereby relegated to “unfair” international treaties that placed the archipelago at a financial disadvantage (Auslin 17).\n",
      "-0.6705\n",
      "Their alienation from the body is augmented by invidious patriarchal demands put on their bodies coupled with strait conditions of poverty.\n",
      "-0.6597\n"
     ]
    }
   ],
   "source": [
    "import tm\n",
    "\n",
    "for i,sentence in enumerate(tm.sorted_by_value(female_sentences)):\n",
    "    if i< 15:\n",
    "        sentence_cleaned = re.sub('\\s+',' ',sentence)\n",
    "        print(f\"{sentence_cleaned}\\n{female_sentences[sentence]}\")\n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
